services:
  neo4j:
    image: neo4j:4.4-community
    volumes:
      - /$HOME/neo4j/logs:/logs
      - /$HOME/neo4j/config:/config
      - /$HOME/neo4j/data:/data
      - /$HOME/neo4j/plugins:/plugins
    environment:
      - NEO4J_AUTH=neo4j/password
      - NEO4J_PLUGINS=["graph-data-science"]
    ports:
      - "7474:7474"
      - "7687:7687"
    restart: always
    networks:
      - scraper-network
      - spark-net
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider localhost:7474 || exit 1" ]

  web-scraper:
    build:
      context: ./web-scraper
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
    ports:
      - 8000:8000
    depends_on:
      neo4j:
        condition: service_healthy
    environment:
      - NEO4J_URI=bolt://neo4j:password@neo4j:7687
    networks:
      - scraper-network
    profiles:
      - scraper

  # jupyterlab:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile.notebook
  #     args:
  #       openjdk_version: "17"
  #       spark_version: "3.5.5"
  #       hadoop_version: "3.3"
  #       spark_download_url: "https://archive.apache.org/dist/spark/"
  #       base_image: "quay.io/jupyter/pyspark-notebook"
  #   image: pyspark3.5.5-notebook
  #   container_name: pyspark-notebook
  #   command: start-notebook.py --NotebookApp.token=''
  #   ports:
  #     - 8888:8888
  #     - 4040:4040
  #   volumes:
  #     - shared-workspace:/home/jovyan/work
  #   networks:
  #     - spark-net

  spark:
    build:
      context: .
      dockerfile: Dockerfile.spark
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    ports:
      - '8080:8080'
      - '7077:7077'
    volumes:
      # - shared-workspace:/vol
      - ./data:${PWD}/data:rw
    networks:
      - spark-net

  spark-worker:
    build:
      context: .
      dockerfile: Dockerfile.spark
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    depends_on:
      - spark
    deploy:
      replicas: 1
    volumes:
      # - shared-workspace:/vol
      - ./data:${PWD}/data:rw
    networks:
      - spark-net

volumes:
  shared-workspace:
    driver: local
    driver_opts:
      type: "none"
      o: "bind"
      device: "${PWD}" # Current directory

networks:
  scraper-network:
    driver: bridge
  spark-net:
    driver: bridge
